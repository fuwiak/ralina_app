# streamlit_app.py  ‚Äî  —Å–æ–≤–º–µ—Å—Ç–∏–º —Å .h5, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å —Å–ª–æ–π ‚ÄúCast/TFOpLambda‚Äù
# --------------------------------------------------------------------------

import streamlit as st, tensorflow as tf, numpy as np, tempfile, os, sys, subprocess, importlib

# ‚îÄ‚îÄ‚îÄ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∏–º–ø–æ—Ä—Ç OpenCV (headless) ‚îÄ‚îÄ‚îÄ
def safe_import_cv2():
    try:
        return importlib.import_module("cv2")
    except ImportError:
        subprocess.check_call([sys.executable, "-m", "pip", "install",
                               "--quiet", "opencv-python-headless==4.7.0.72"])
        return importlib.import_module("cv2")
cv2 = safe_import_cv2()

# ‚îÄ‚îÄ‚îÄ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã ‚îÄ‚îÄ‚îÄ
IMG = 150
STEP = 10
THR  = 0.60        # –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ ¬´–µ—Å—Ç—å –æ–±–≤–∞–ª¬ª
COLLAPSE = ["No_Landslide", "Rockfall", "Earth_Flow"]
DANGER   = ["Safe", "Roads_Damaged", "Houses_Damaged"]

# ‚îÄ‚îÄ‚îÄ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è ¬´–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö¬ª —Å–ª–æ—ë–≤ –∏–∑ .h5 ‚îÄ‚îÄ‚îÄ
CUSTOM_OBJECTS = {
    "Cast":        tf.keras.layers.Lambda,   # —Å—Ç–∞—Ä—ã–π —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–∏—à–µ—Ç Cast
    "TFOpLambda":  tf.keras.layers.Lambda,   # Keras-3 –ø–∏—à–µ—Ç TFOpLambda
}

@st.cache_resource(show_spinner=False)
def load_models():
    coll = tf.keras.models.load_model("collapse_model (1).h5",
                                      compile=False,
                                      custom_objects=CUSTOM_OBJECTS) \
           if os.path.exists("collapse_model (1).h5") else None

    if not os.path.exists("danger_model (1).h5"):
        st.error("–§–∞–π–ª **danger_model (1).h5** –Ω–µ –Ω–∞–π–¥–µ–Ω."); st.stop()

    dang = tf.keras.models.load_model("danger_model (1).h5",
                                      compile=False,
                                      custom_objects=CUSTOM_OBJECTS)
    return coll, dang
collapse_model, danger_model = load_models()

# ‚îÄ‚îÄ‚îÄ –≤–∏–¥–µ–æ ‚Üí (—Ç–∏–ø –æ–±–≤–∞–ª–∞, –µ–≥–æ conf, –æ–ø–∞—Å–Ω–æ—Å—Ç—å, –µ—ë conf) ‚îÄ‚îÄ‚îÄ
def analyse_video(path):
    cap = cv2.VideoCapture(path)
    if not cap.isOpened(): return None
    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
    step_prog = max(total//100, 1)
    prog = st.progress(0)

    v_coll = np.zeros(3,int) if collapse_model is not None else None
    v_dang = np.zeros(3,int)
    fid = 0
    while True:
        ok, frame = cap.read()
        if not ok: break
        if fid % STEP == 0:
            fr = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), (IMG, IMG))
            inp = np.expand_dims(fr,0)/255.
            if collapse_model is not None:
                p = collapse_model.predict(inp, verbose=0)[0]
                v_coll[np.argmax(p)] += 1
            q = danger_model.predict(inp, verbose=0)[0]
            v_dang[np.argmax(q)] += 1
        if fid % step_prog == 0:
            prog.progress(min(fid/max(total,1), 1.0))
        fid += 1
    cap.release(); prog.empty()

    # –∏—Ç–æ–≥ collapse
    if collapse_model is not None:
        conf_c = v_coll.max()/v_coll.sum() if v_coll.sum() else 0
        cls_c  = COLLAPSE[v_coll.argmax()]
        if conf_c < THR:
            cls_c, conf_c = "No_Landslide", 1-conf_c
    else:
        cls_c, conf_c = None, None

    conf_d = v_dang.max()/v_dang.sum() if v_dang.sum() else 0
    cls_d  = DANGER[v_dang.argmax()]

    return cls_c, conf_c, cls_d, conf_d

# ‚îÄ‚îÄ‚îÄ UI ‚îÄ‚îÄ‚îÄ
st.set_page_config("Landslide Detection", "üåã", layout="centered")
st.title("üåã Landslide Detection")

st.write(
"–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ (*.mp4, *.avi, *.mov, *.mkv*) –∏ –Ω–∞–∂–º–∏—Ç–µ **–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å**. "
"–ï—Å–ª–∏ `collapse_model.h5` –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø–æ–∫–∞–∂–µ—Ç —Ç–æ–ª—å–∫–æ –æ–ø–∞—Å–Ω–æ—Å—Ç—å."
)

file = st.file_uploader("–í–∏–¥–µ–æ-—Ñ–∞–π–ª", type=["mp4","avi","mov","mkv"])
if file:
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    tmp.write(file.read()); tmp.close()
    st.video(tmp.name)

    if st.button("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å"):
        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞‚Ä¶"):
            res = analyse_video(tmp.name)
        os.unlink(tmp.name)            # –æ—á–∏—â–∞–µ–º tmp
        if res is None:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –≤–∏–¥–µ–æ.")
        else:
            c_cls,c_conf,d_cls,d_conf = res
            if c_cls is not None:
                st.info(f"**–¢–∏–ø –æ–±–≤–∞–ª–∞:** {c_cls}  ({c_conf*100:.1f} %)")
            st.success(f"**–û–ø–∞—Å–Ω–æ—Å—Ç—å:** {d_cls}  ({d_conf*100:.1f} %)")
else:
    st.caption("‚¨ÜÔ∏è  –í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
